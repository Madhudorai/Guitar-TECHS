{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMMyPZTLS9tM"
      },
      "source": [
        "# Installation and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eaQrtf2hHdK6",
        "outputId": "c7575fc9-d4a9-448d-cf92-a210455826cd"
      },
      "outputs": [],
      "source": [
        "!pip install pretty-midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mM4NxHsSsR1"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import librosa\n",
        "import pretty_midi\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from IPython.display import display, Audio\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import random\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import requests\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtFDOv2_Tcyj"
      },
      "source": [
        "# Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn_dUntFgvD4"
      },
      "outputs": [],
      "source": [
        "class GuitarTECHSDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Filters and Attributes:\n",
        "      - root_dir (str): Base directory where the dataset is stored.\n",
        "      - sr (int): Target audio sample rate (Hz) used for loading audio (default: 48000).\n",
        "      - players (list): Which player folders to use (e.g., ['P1', 'P2'] or ['all'] for all players).\n",
        "      - content_types (list): Which content types to include (e.g., ['chords', 'scales', 'singlenotes', 'techniques'] for P1/P2, or ['music'] for P3, or 'all').\n",
        "      - modalities (list): Subset of [\"directinput\", \"micamp\", \"exo\", \"ego\"] indicating which data streams to load.\n",
        "      - slice_dur (float): If specified (in seconds), samples are segmented into contiguous slices of this length.\n",
        "                           The last slice, if shorter than slice_dur, will be padded with zeros.\n",
        "      - slice_range (tuple): Alternatively, a fixed (start, end) time window for all samples (in seconds).\n",
        "                             Only one of slice_dur and slice_range may be set.\n",
        "      - slice_overlap(float): overlap time between consecutive slices. Has to be < slice_dur\n",
        "\n",
        "    Main Methods:\n",
        "      - __init__(): Initializes the dataset by downloading & extracting the data (if not already present), scanning\n",
        "                    the appropriate subfolders for directinput files, building an index of samples, and constructing an\n",
        "                    expanded index with slice boundaries using the MIDI file durations.\n",
        "      - __len__(): Returns the number of available slices (or full samples if no slicing is applied).\n",
        "      - _get_base_dir(player, content): Constructs the expected base directory for a given player and content type.\n",
        "                                          Follows the naming convention \"<player>_<content.lower()>\", using a nested\n",
        "                                          folder if available.\n",
        "      - _get_midi_path(item): Returns the full path to the MIDI file corresponding to a given sample.\n",
        "      - load_audio(path): Loads an audio file from a given path at the defined sample rate.\n",
        "      - slice_audio(audio, start, end): Extracts a segment of the audio between the given start and end times.\n",
        "                                        If the slice is shorter than the expected duration, it pads the segment with zeros.\n",
        "      - parse_midi(midi_obj, start, end): Extracts note information from a PrettyMIDI object for notes within the [start, end) window.\n",
        "                                         Each note label includes 'note', 'onset', 'offset', 'string', and 'fret'.\n",
        "      - pitch_to_fret(midi_note): Maps a MIDI note number to a fret number based on a default tuning (returns None if not valid).\n",
        "      - __getitem__(idx): Retrieves a single data slice, including:\n",
        "            • Metadata: player, content_type, sample identifier, chord_type (if applicable)\n",
        "            • Data: Sliced (and padded) audio/video modalities\n",
        "            • Labels: MIDI note information for the slice\n",
        "            • Timing: The actual slice start and end timestamps\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 root_dir='Guitar-TECHS',\n",
        "                 sr=48000,\n",
        "                 players=['all'],\n",
        "                 content_types='all',\n",
        "                 modalities='all',\n",
        "                 slice_dur=None,\n",
        "                 slice_range=None):\n",
        "      \n",
        "        if slice_dur and slice_range:\n",
        "            raise ValueError(\"Cannot specify both slice_dur and slice_range.\")\n",
        "        if slice_overlap >= slice_dur:\n",
        "            raise ValueError(\"slice_overlap must be less than slice_dur.\")\n",
        "        self.root_dir = root_dir\n",
        "        if not os.path.exists(self.root_dir):\n",
        "           self._download_and_extract_dataset()\n",
        "        self.sr = sr\n",
        "        self.slice_dur = slice_dur\n",
        "        self.slice_range = slice_range\n",
        "        self.slice_overlap = slice_overlap\n",
        "\n",
        "        # Define available players and content types.\n",
        "        AVAILABLE_PLAYERS = ['P1', 'P2', 'P3']\n",
        "        AVAILABLE_CONTENT = {\n",
        "            'P1': ['chords', 'scales', 'singlenotes', 'techniques'],\n",
        "            'P2': ['chords', 'scales', 'singlenotes', 'techniques'],\n",
        "            'P3': ['music']\n",
        "        }\n",
        "        VALID_MODALITIES = ['directinput', 'micamp', 'exo', 'ego']\n",
        "\n",
        "        self.players = AVAILABLE_PLAYERS if players in ['all', ['all']] else players\n",
        "        assert all(p in AVAILABLE_PLAYERS for p in self.players), \\\n",
        "            f\"Players must be a subset of {AVAILABLE_PLAYERS}\"\n",
        "        self.modalities = VALID_MODALITIES if modalities in ['all', ['all']] else modalities\n",
        "        assert all(m in VALID_MODALITIES for m in self.modalities), \\\n",
        "            f\"Modalities must be a subset of {VALID_MODALITIES}\"\n",
        "\n",
        "        self.index = []\n",
        "\n",
        "        # Build sample index by scanning directinput files.\n",
        "        for player in self.players:\n",
        "            valid_contents = AVAILABLE_CONTENT[player]\n",
        "            selected_contents = valid_contents if content_types in ['all', ['all']] else content_types\n",
        "            for content in selected_contents:\n",
        "                if content not in valid_contents:\n",
        "                    print(f\"Skipping content '{content}' for player '{player}' — not available in this player's dataset.\")\n",
        "                    continue\n",
        "                # Construct the base directory. Note: folder naming uses lower-case for content.\n",
        "                base_dir = self._get_base_dir(player, content)\n",
        "                di_dir = os.path.join(base_dir, 'audio', 'directinput')\n",
        "                if os.path.exists(di_dir):\n",
        "                    for fname in os.listdir(di_dir):\n",
        "                        if fname.startswith('directinput_') and fname.endswith('.wav'):\n",
        "                            # The sample identifier is based on the file name.\n",
        "                            sample_value = fname.replace('directinput_', '').replace('.wav', '')\n",
        "                            chord_type = None\n",
        "                            if content.lower() == 'chords':\n",
        "                                prefix = sample_value.split('_')[0]\n",
        "                                if prefix in ['Set1', 'Set2', 'Set3', 'Set4']:\n",
        "                                    chord_type = '3-note chord'\n",
        "                                elif prefix == 'Drop3':\n",
        "                                    chord_type = '4-note chord'\n",
        "                            self.index.append({\n",
        "                                'player': player,\n",
        "                                'content_type': content,\n",
        "                                'sample': sample_value,\n",
        "                                'chord_type': chord_type\n",
        "                            })\n",
        "\n",
        "        if self.slice_dur:\n",
        "          self.expanded_index = []\n",
        "          for i, sample_meta in enumerate(self.index):\n",
        "              base_dir = self._get_base_dir(sample_meta['player'], sample_meta['content_type'])\n",
        "              # use micamp for total length \n",
        "              audio_path = os.path.join(base_dir, 'audio', 'micamp', f\"micamp_{sample_meta['sample']}.wav\")\n",
        "\n",
        "              if not os.path.exists(audio_path):\n",
        "                  continue\n",
        "\n",
        "              duration = librosa.get_duration(path=audio_path)\n",
        "              total_samples = int(duration * self.sr)\n",
        "\n",
        "              # Load full audio\n",
        "              y, _ = librosa.load(audio_path, sr=self.sr)\n",
        "\n",
        "              slice_samples = int(self.slice_dur * self.sr)\n",
        "              overlap_samples = int(self.slice_overlap * self.sr)\n",
        "              hop_length = slice_samples - overlap_samples\n",
        "\n",
        "              # Pad the signal \n",
        "              pad_width = (slice_samples - len(y) % hop_length) % hop_length\n",
        "              y_padded = np.pad(y, (0, pad_width), mode='constant')\n",
        "\n",
        "              # Use librosa utils for slicing \n",
        "              frames = librosa.util.frame(y_padded, frame_length=slice_samples, hop_length=hop_length)\n",
        "\n",
        "              # For each frame, compute start and end time (in seconds)\n",
        "              for s in range(frames.shape[1]):\n",
        "                  start_sample = s * hop_length\n",
        "                  start_sec = start_sample / self.sr\n",
        "                  end_sec = start_sec + self.slice_dur\n",
        "                  self.expanded_index.append((i, start_sec, end_sec))\n",
        "\n",
        "\n",
        "    def _download_and_extract_dataset(self):\n",
        "        \"\"\"\n",
        "        Downloads and extracts the Guitar-TECHS dataset if it's not already present.\n",
        "        Uses a progress bar to show download progress.\n",
        "        \"\"\"\n",
        "        print(f\"{self.root_dir} not found. Downloading dataset...\")\n",
        "\n",
        "        zip_path = \"dataset.zip\"\n",
        "        url = \"https://zenodo.org/api/records/14963133/files-archive\"\n",
        "\n",
        "        # Define known total size in bytes (3942.06 MB)\n",
        "        total_size = int(3942.06 * 1024 * 1024)\n",
        "        block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "        response = requests.get(url, stream=True)\n",
        "\n",
        "        with open(zip_path, 'wb') as f, tqdm(\n",
        "            desc=\"Downloading\",\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar:\n",
        "            for data in response.iter_content(block_size):\n",
        "                f.write(data)\n",
        "                bar.update(len(data))\n",
        "\n",
        "        print(\"Download complete. Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.root_dir)\n",
        "        os.remove(zip_path)\n",
        "\n",
        "        self._extract_nested_zip(self.root_dir)\n",
        "        print(\"Dataset downloaded and extracted successfully.\")\n",
        "\n",
        "\n",
        "    def _extract_nested_zip(self, root_dir):\n",
        "        \"\"\"\n",
        "        Recursively extracts all zip files found within the directory tree starting at root_dir.\n",
        "        After extraction, the original zip files are removed.\n",
        "        \"\"\"\n",
        "        for foldername, subfolders, filenames in os.walk(root_dir):\n",
        "            for filename in filenames:\n",
        "                if filename.endswith('.zip'):\n",
        "                    zip_path = os.path.join(foldername, filename)\n",
        "                    extract_path = os.path.splitext(zip_path)[0]  # Folder name without .zip\n",
        "                    print(\"Extracting:\", zip_path, \"to\", extract_path)\n",
        "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(extract_path)\n",
        "                    os.remove(zip_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.expanded_index)\n",
        "\n",
        "    def _get_base_dir(self, player, content):\n",
        "        \"\"\"\n",
        "        Constructs the base directory for a given player and content type.\n",
        "        Expected naming: \"<player>_<content.lower()>\", and inside that folder may be a nested folder of the same name.\n",
        "        \"\"\"\n",
        "        dir_name = f\"{player}_{content.lower()}\"\n",
        "        candidate = os.path.join(self.root_dir, dir_name)\n",
        "        nested = os.path.join(candidate, dir_name)\n",
        "        return nested if os.path.exists(nested) else candidate\n",
        "\n",
        "    def _get_midi_path(self, item):\n",
        "        base_dir = self._get_base_dir(item['player'], item['content_type'])\n",
        "        return os.path.join(base_dir, 'midi', f\"midi_{item['sample']}.mid\")\n",
        "\n",
        "    def load_audio(self, path):\n",
        "        audio, _ = librosa.load(path, sr=self.sr)\n",
        "        return audio\n",
        "\n",
        "    def slice_audio(self, audio, start, end):\n",
        "        \"\"\"\n",
        "        Returns a slice of the audio corresponding to [start, end) seconds. When using slice_dur,\n",
        "        if the extracted segment is shorter than the desired slice length (i.e. (end - start) * sr),\n",
        "        it is padded with zeros at the end.\n",
        "        \"\"\"\n",
        "        start_sample = int(start * self.sr)\n",
        "        # Determine desired slice length in samples.\n",
        "        desired_length = int(self.slice_dur * self.sr) if self.slice_dur else int((end - start) * self.sr)\n",
        "        end_sample = start_sample + desired_length\n",
        "        segment = audio[start_sample: min(len(audio), end_sample)]\n",
        "        if len(segment) < desired_length:\n",
        "            segment = np.pad(segment, (0, desired_length - len(segment)), mode='constant')\n",
        "        return segment\n",
        "\n",
        "    def parse_midi(self, midi_obj, start=None, end=None):\n",
        "        \"\"\"\n",
        "        Extracts MIDI note information from a PrettyMIDI object.\n",
        "        Only considers notes that fall (at least partially) within the [start, end) window.\n",
        "        Onset and offset times in the label are relative to the start time.\n",
        "        \"\"\"\n",
        "        labels = []\n",
        "        for string_index, instrument in enumerate(midi_obj.instruments):\n",
        "            for note in instrument.notes:\n",
        "                # Skip notes that lie entirely outside the window.\n",
        "                if start is not None and (note.end <= start or note.start >= end):\n",
        "                    continue\n",
        "                onset = max(note.start, start) if start else note.start\n",
        "                offset = min(note.end, end) if end else note.end\n",
        "                labels.append({\n",
        "                    'note': note.pitch,\n",
        "                    'onset': onset - start if start else onset,\n",
        "                    'offset': offset - start if start else offset,\n",
        "                    'string': string_index + 1,\n",
        "                    'fret': self.pitch_to_fret(note.pitch)\n",
        "                })\n",
        "        return labels\n",
        "\n",
        "    def pitch_to_fret(self, midi_note, tuning=[40, 45, 50, 55, 59, 64]):\n",
        "        for string_midi in tuning[::-1]:\n",
        "            fret = midi_note - string_midi\n",
        "            if 0 <= fret <= 24:\n",
        "                return fret\n",
        "        return None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx, start, end = self.expanded_index[idx]\n",
        "        item = self.index[real_idx]\n",
        "        base_dir = self._get_base_dir(item['player'], item['content_type'])\n",
        "\n",
        "        data = {}\n",
        "        # Load each modality.\n",
        "        for dtype in self.modalities:\n",
        "            if dtype in ['directinput', 'micamp']:\n",
        "                folder = os.path.join('audio', dtype)\n",
        "                ext = '.wav'\n",
        "            elif dtype in ['exo', 'ego']:\n",
        "                folder = os.path.join('video', dtype)\n",
        "                ext = '.mp3'\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            path = os.path.join(base_dir, folder, f\"{dtype}_{item['sample']}{ext}\")\n",
        "            if os.path.exists(path):\n",
        "                modality_data = self.load_audio(path)\n",
        "                # Slice (and pad if needed) the audio for the desired time window.\n",
        "                data[dtype] = self.slice_audio(modality_data, start, end) if start is not None else modality_data\n",
        "            else:\n",
        "                data[dtype] = None\n",
        "\n",
        "        # Process MIDI labels for the corresponding time window.\n",
        "        midi_path = self._get_midi_path(item)\n",
        "        if os.path.exists(midi_path):\n",
        "            midi_obj = pretty_midi.PrettyMIDI(midi_path)\n",
        "            labels = self.parse_midi(midi_obj, start, end)\n",
        "        else:\n",
        "            labels = []\n",
        "\n",
        "        # If no MIDI labels are found, you can choose to return None or an empty dict.\n",
        "        if not labels:\n",
        "            return None\n",
        "\n",
        "        # Return the sample dictionary including sample name and slice timestamps.\n",
        "        return {\n",
        "            'player': item['player'],\n",
        "            'content_type': item['content_type'],\n",
        "            'sample': item['sample'],\n",
        "            'chord_type': item.get('chord_type'),\n",
        "            'data': data,\n",
        "            'labels': labels,\n",
        "            'midi_path': midi_path,\n",
        "            'slice_start': start,\n",
        "            'slice_end': end\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJP-W8C-wWpR"
      },
      "source": [
        "#Initialising the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcCB___uIn_E",
        "outputId": "8e1e85c3-4145-448e-f66e-e88743f61e55"
      },
      "outputs": [],
      "source": [
        "dataset = GuitarTECHSDataset(\n",
        "    root_dir='Guitar-TECHS',\n",
        "    players=['all'],\n",
        "    content_types=['all'],\n",
        "    modalities=['all'],\n",
        "    slice_dur=5, slice_overlap= 1  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFdHwQuj4RD2",
        "outputId": "a503b26b-5fee-43ca-d493-885f24b20695"
      },
      "outputs": [],
      "source": [
        "print(\"Number of samples/slices:\", len(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Looking at samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "7BeJgH4V5YkW",
        "outputId": "24ce9494-e733-45c1-ce1f-99cdfe4e3e86"
      },
      "outputs": [],
      "source": [
        "# Get a sample from the dataset\n",
        "sample = dataset[1000]\n",
        "\n",
        "# Print basic sample metadata\n",
        "print(\"Sample name:\", sample['sample'])\n",
        "print(\"Player:\", sample['player'])\n",
        "print(\"Content type:\", sample['content_type'])\n",
        "if 'chord_type' in sample:\n",
        "    print(\"Chord type:\", sample['chord_type'])\n",
        "print(\"Slice time:\", sample['slice_start'], \"to\", sample['slice_end'])\n",
        "\n",
        "# Display label information as a table\n",
        "labels_df = pd.DataFrame(sample['labels'])\n",
        "labels_df_sorted = labels_df.sort_values(by='onset').reset_index(drop=True)\n",
        "display(labels_df_sorted)\n",
        "\n",
        "# Play each modality if available (directinput, micamp, exo, ego)\n",
        "for modality in ['directinput', 'micamp', 'exo', 'ego']:\n",
        "    modality_data = sample['data'].get(modality)\n",
        "    if modality_data is not None:\n",
        "        print(f\"\\nPlaying {modality} modality:\")\n",
        "        display(Audio(modality_data, rate=dataset.sr))\n",
        "    else:\n",
        "        print(f\"\\nModality '{modality}' is not available for this sample.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the consecutive/next sample from the dataset (to observe slice times overlap)\n",
        "sample = dataset[1001]\n",
        "\n",
        "# Print basic sample metadata\n",
        "print(\"Sample name:\", sample['sample'])\n",
        "print(\"Player:\", sample['player'])\n",
        "print(\"Content type:\", sample['content_type'])\n",
        "if 'chord_type' in sample:\n",
        "    print(\"Chord type:\", sample['chord_type'])\n",
        "print(\"Slice time:\", sample['slice_start'], \"to\", sample['slice_end'])\n",
        "\n",
        "# Display label information as a table\n",
        "labels_df = pd.DataFrame(sample['labels'])\n",
        "labels_df_sorted = labels_df.sort_values(by='onset').reset_index(drop=True)\n",
        "display(labels_df_sorted)\n",
        "\n",
        "# Play each modality if available (directinput, micamp, exo, ego)\n",
        "for modality in ['directinput', 'micamp', 'exo', 'ego']:\n",
        "    modality_data = sample['data'].get(modality)\n",
        "    if modality_data is not None:\n",
        "        print(f\"\\nPlaying {modality} modality:\")\n",
        "        display(Audio(modality_data, rate=dataset.sr))\n",
        "    else:\n",
        "        print(f\"\\nModality '{modality}' is not available for this sample.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
